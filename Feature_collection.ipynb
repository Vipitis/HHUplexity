{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84f57cc7",
   "metadata": {},
   "source": [
    "# Collection of some Features for HHUplexity\n",
    "\n",
    "Please copy the data of the shared task first into the \"data/\" directory.\n",
    "All features generated in this file will be saved in \"data/feats/[train|dev|test]\\_1\". If you also use the other files to generate features, they will be saved in other files. Please consider to merge all features into one file for training.\n",
    "\n",
    "This files contains the generation of the following features:\n",
    "* [Features based on Compound Nouns ](#Features-based-on-Compound-Nouns)\n",
    "* [Features based on the Morphological Analyzer of Spacy](#Features-based-on-the-Morphological-Analyzer-of-Spacy)\n",
    "* [Feature based on Dependency Tree Distance](#Feature-based-on-Dependency-Tree-Distance)\n",
    "* [Features based on Verb-Noun-Ratio](#Features-based-on-Verb-Noun-Ratio)\n",
    "* [Features based on Negations](#Features-based-on-Negations)\n",
    "* [Features based on POS Tags](#Features-based-on-POS-Tags)\n",
    "* [Features based on Imageability and concreteness](#Features-based-on-Imageability-and-concreteness)\n",
    "* [Feature based on TSeval package](#Feature-based-on-TSeval-package)\n",
    "* [Features based on Perplexity Score of Language Models](#Features-based-on-Perplexity-Score-of-Language-Models)\n",
    "* [Text Leveling as Feature for Complexity Prediction](#Text-Leveling-as-Feature-for-Complexity-Prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c7bb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdad930",
   "metadata": {},
   "source": [
    "## Read Data\n",
    "- make sure that you copied the data of the shared task in the right directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d14d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"data/public_data_text_complexity22/training_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d925cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dev = pd.read_csv(\"data/public_data_text_complexity22/validation_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36116bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"data/public_data_text_complexity22/part2_public.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c2265c",
   "metadata": {},
   "source": [
    "## Features based on Compound Nouns \n",
    "**Idea:**\n",
    "- The longer the words, the more diffult to understand them. \n",
    "- The more lexemes are compounded in a word, the more difficult to understand the word.\n",
    "- The more words are compounded of several lexems, the more complex the sentence.\n",
    "- The more nouns are compounded of several lexemes, the more complex the sentence.\n",
    "\n",
    "**Result:**\n",
    "- weak correlation between MOS and ratio of compound words to all words (r=0.224703)\n",
    "- low correlation between MOS and ratio of compound words to all words (r=0.165764"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6e6100",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install git+https://github.com/repodiac/german_compound_splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad6bdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import german_compound_splitter\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7ba8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"de_core_news_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58af8767",
   "metadata": {},
   "outputs": [],
   "source": [
    "from german_compound_splitter import comp_split\n",
    "\n",
    "# please load an appropriate (external) dictionary, see the notes in section Installation/Setup on the dictionary\n",
    "input_file = 'data/german.dic'\n",
    "ahocs = comp_split.read_dictionary_from_file(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61d8cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ratio_compounds_per_sent(tokens: list, ahocs=ahocs, only_nouns=False):\n",
    "    \"\"\"\n",
    "    Calculate the ratio of input tokens which are compounded. \n",
    "    tokens: list of tokens of a sentence or a text\n",
    "    ahocs: german dictionary of words (https://sourceforge.net/projects/germandict/files/latest/download)\n",
    "    only_nouns: specify if only the ratio of compound nouns or all compund words should be calculated.\n",
    "    \n",
    "    returns the rounded ratio of compound tokens/nouns to all tokens/nouns\n",
    "    \"\"\"\n",
    "\n",
    "    num_compounds = 0\n",
    "    num_nouns = 0\n",
    "    for token in tokens:\n",
    "        try:\n",
    "            if only_nouns:\n",
    "                dissection = comp_split.dissect(token.text, ahocs, make_singular=False, mask_unknown=True, only_nouns=True)\n",
    "            else:\n",
    "                dissection = comp_split.dissect(token.text, ahocs, make_singular=False, mask_unknown=True, only_nouns=False)\n",
    "            if len(dissection) > 1:\n",
    "                num_compounds += 1\n",
    "        except IndexError:\n",
    "            print(\"word:\", token, \"not in dictionary.\")\n",
    "        if token.pos_ == (\"NOUN\"):\n",
    "            num_nouns += 1\n",
    "    if only_nouns:\n",
    "        if num_nouns == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return round(num_compounds/num_nouns,6)\n",
    "    else:\n",
    "        return round(num_compounds/len(tokens),6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92977ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_ratio_compounds(data):\n",
    "    \"\"\"\n",
    "    calculate the ratio of compound words, i.e., the ratio of all compound tokens to all tokens \n",
    "    and all compound nouns to all nouns.\n",
    "    \n",
    "    data: dataframe with the text in the sentence column\n",
    "    \n",
    "    returns the dataset with new columns regarding the compound words features\n",
    "    \"\"\"\n",
    "    for i, row in data.iterrows():\n",
    "        tokens = list(nlp(row[\"Sentence\"]))\n",
    "        data.loc[i,\"F_compound_ratio\"] = ratio_compounds_per_sent(tokens)\n",
    "        data.loc[i,\"F_compound_nouns_ratio\"] = ratio_compounds_per_sent(tokens, only_nouns=True) \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d93aa2",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c265a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "compound = 'Donaudampfschifffahrtskapitänsmützenabzeichen'\n",
    "\n",
    "dissection = comp_split.dissect(compound, ahocs, make_singular=True)\n",
    "print('SPLIT WORDS (plain):', dissection)\n",
    "print('SPLIT WORDS (post-merge):', comp_split.merge_fractions(dissection))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c333f3",
   "metadata": {},
   "source": [
    "### Real Data\n",
    "- add new features of compound words to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0eb4c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = feature_ratio_compounds(train_data)\n",
    "data_dev = feature_ratio_compounds(data_dev)\n",
    "test_data = feature_ratio_compounds(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe95c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_correlation_table = train_data[[\"MOS\", \"F_compound_ratio\", \"F_compound_nouns_ratio\"]].corr()\n",
    "data_correlation_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397d03f6",
   "metadata": {},
   "source": [
    "## Features based on the Morphological Analyzer of Spacy\n",
    "**Idea:**\n",
    "- subjunctive sentence are more difficult to understand than indicative sentences\n",
    "- some German cases are more difficult to understand than others, e.g., the genitive is often named as difficult to understand therefore often replaced by the dative\n",
    "\n",
    "\n",
    "**Result:**\n",
    "- low correlation between MOS and boolean featuer of subjunctive/indicative (r=0.137552)\n",
    "- no correlation between MOS and ratio of nouns in nominative to all nouns (r=-0.031380)\n",
    "- moderate correlation between MOS and ratio of genitive in nominative to all nouns (r=0.251906)\n",
    "- no correlation between MOS and ratio of dative in nominative to all nouns (r=0.086093)\n",
    "- low correlation between MOS and ratio of accusative in nominative to all nouns (r=-0.142144)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61dde60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_subjunctive(tokens):\n",
    "    \"\"\"\n",
    "    tokens: list of spacy.Token objects\n",
    "\n",
    "    returns 1 if a part of the sentence is subjunctive, 0 if not.\n",
    "    \"\"\"\n",
    "    for token in tokens:\n",
    "        if \"Mood=Sub\" in token.morph:\n",
    "            return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfd4b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ratio_case(tokens):\n",
    "    \"\"\"\n",
    "    tokens: list of spacy.Token objects\n",
    "\n",
    "    returns ratio of nouns in all four cases.\n",
    "    \"\"\"\n",
    "    num_nouns = 0\n",
    "    num_nom = 0\n",
    "    num_gen = 0\n",
    "    num_dat = 0\n",
    "    num_acc = 0\n",
    "    for token in tokens:\n",
    "        if token.pos_ == \"NOUN\":\n",
    "            num_nouns += 1\n",
    "            if \"Case=Nom\" in token.morph:\n",
    "                num_nom += 1\n",
    "            elif \"Case=Gen\" in token.morph:\n",
    "                num_gen += 1\n",
    "            elif \"Case=Dat\" in token.morph:\n",
    "                num_dat += 1\n",
    "            elif \"Case=Acc\" in token.morph:\n",
    "                num_acc += 1\n",
    "    if num_nouns == 0:\n",
    "        return 0, 0, 0, 0\n",
    "    return round(num_nom/num_nouns,6), round(num_gen/num_nouns,6), round(num_dat/num_nouns,6), round(num_acc/num_nouns,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0522872f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_mophology(data):\n",
    "    \"\"\"\n",
    "    calculate the ratio of nouns in nominative, genitive, dative and accusative to all nouns. \n",
    "    Also check if a sentence is written subjunctively or indicatively.\n",
    "    \n",
    "    data: dataframe with the text in the sentence column\n",
    "    \n",
    "    returns the dataset with new columns regarding the morphology features\n",
    "    \"\"\"\n",
    "        \n",
    "    for i, row in data.iterrows():\n",
    "        tokens = list(nlp(row[\"Sentence\"]))\n",
    "        data.loc[i,\"F_subjunctive\"] = is_subjunctive(tokens)\n",
    "        ratio_nom, ratio_gen, ratio_dat, ratio_acc = ratio_case(tokens)\n",
    "        data.loc[i,\"F_ratio_nom\"] = ratio_nom\n",
    "        data.loc[i,\"F_ratio_gen\"] = ratio_gen\n",
    "        data.loc[i,\"F_ratio_dat\"] = ratio_dat\n",
    "        data.loc[i,\"F_ratio_acc\"] = ratio_acc\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d0c5b4",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f645c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nlp(\"Der Satz könnte im Dativ geschrieben sein.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e39277",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_case(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e565ff2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_subjunctive(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af0e9ad",
   "metadata": {},
   "source": [
    "### Real Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b324ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = feature_mophology(train_data)\n",
    "data_dev = feature_mophology(data_dev)\n",
    "test_data = feature_mophology(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3572e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_correlation_table = train_data[[\"MOS\", \"F_subjunctive\", \"F_ratio_nom\", \"F_ratio_gen\", \"F_ratio_dat\", \"F_ratio_acc\"]].corr()\n",
    "data_correlation_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4315f74c",
   "metadata": {},
   "source": [
    "## Feature based on Dependency Tree Distance\n",
    "**Idea:**\n",
    "- Words which are discontinuously connected in a sentence  are more difficult to understand because the reader need to memorize more elements of the sentence to combine the meaning.\n",
    "\n",
    "**Results:**\n",
    "- moderate correlation between MOS and average distance between words (r=0.594131)\n",
    "- weak correlation between MOS and maximum distance between words (r=0.217165)\n",
    "- no correlation between MOS and maximum distance between verbs and particle verbs (r=0.064130)\n",
    "- no correlation between MOS and maximum distance between verbs and particle verbs (r=0.064669)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddd80e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_between_words(tokens):\n",
    "    \"\"\"\n",
    "    tokens: list of spacy.Token objects\n",
    "    calculate the average and the maximum distance between nodes in the dependency tree\n",
    "    \n",
    "    return average and max distance value\n",
    "    \"\"\"\n",
    "    max_distance = 0\n",
    "    list_distances = list()\n",
    "    for token in tokens:\n",
    "        distance = abs(token.i-token.head.i)\n",
    "        list_distances.append(distance)\n",
    "        if distance > max_distance:\n",
    "            max_distance = distance\n",
    "    # return round((sum(list_distances)/len(list_distances))/len(tokens),6), round(max_distance/len(tokens),6)\n",
    "    return round(sum(list_distances)/len(list_distances),6), round(max_distance/len(tokens),6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845fbfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_between_verb_particles(tokens):\n",
    "    \"\"\"\n",
    "    tokens: list of spacy.Token objects\n",
    "    calculate the average and the maximum distance between verbs and particle verbs in the dependency tree\n",
    "    \n",
    "    return average and max distance value\n",
    "    \"\"\"\n",
    "    max_distance = 0\n",
    "    list_distances = list()\n",
    "    for token in tokens:\n",
    "        if token.tag_ == \"PTKVZ\":\n",
    "            distance = abs(token.i-token.head.i)\n",
    "            list_distances.append(distance)\n",
    "            if distance > max_distance:\n",
    "                max_distance = distance\n",
    "    if len(list_distances) > 0:\n",
    "        return round((sum(list_distances)/len(list_distances))/len(tokens),6), round(max_distance/len(tokens),6)\n",
    "    else:\n",
    "        return 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd660e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_depency_tree_distance(data):\n",
    "    \"\"\"\n",
    "    calculate the average and maximum distance between nodes in the dependency tree. \n",
    "    And also calculates only the distance between verbs and verb particles.\n",
    "    \n",
    "    data: dataframe with the text in the sentence column\n",
    "    \n",
    "    returns the dataset with new columns regarding the distance features\n",
    "    \"\"\"\n",
    "        \n",
    "    for i, row in data.iterrows():\n",
    "        tokens = list(nlp(row[\"Sentence\"]))\n",
    "        avg_distance, max_distance = distance_between_words(tokens)\n",
    "        data.loc[i,\"F_avg_distance_betweeen_words\"] = avg_distance\n",
    "        data.loc[i,\"F_max_distance_betweeen_words\"] = max_distance\n",
    "        \n",
    "        avg_distance_verb, max_distance_verb = distance_between_verb_particles(tokens)\n",
    "        data.loc[i,\"F_avg_distance_betweeen_verb_particle\"] = avg_distance_verb\n",
    "        data.loc[i,\"F_max_distance_betweeen_verb_particles\"] = max_distance_verb\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8351c445",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc745c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_between_verb_particles(list(nlp(\"Er schlägt das Buch auf .\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0abaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_between_words(list(nlp(\"Er schlägt das Buch auf .\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be78a775",
   "metadata": {},
   "source": [
    "### Real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce630828",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = feature_depency_tree_distance(train_data)\n",
    "data_dev = feature_depency_tree_distance(data_dev)\n",
    "test_data = feature_depency_tree_distance(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816bf71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_correlation_table = train_data[[\"MOS\", \"F_avg_distance_betweeen_words\", \"F_max_distance_betweeen_words\", \"F_avg_distance_betweeen_verb_particle\", \"F_max_distance_betweeen_verb_particles\"]].corr()\n",
    "data_correlation_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe73685b",
   "metadata": {},
   "source": [
    "## Features based on Verb-Noun-Ratio\n",
    "\n",
    "**Idea:**\n",
    "- the more verbs in a sentece, the better to understand the sentence\n",
    "- the more nouns in a sentence, the less to understand the sentence\n",
    "- the more verbs per nouns in a sentence, the better to understand the sentence\n",
    "\n",
    "**Results:**\n",
    "- weak negative correlation between MOS and verb-noun-ratio (r=-0.219467)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbe8595",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verb_noun_ratio(tokens):\n",
    "    \"\"\"\n",
    "    tokens: list of Spacy.Token objects\n",
    "    calcualtes the ratio from verbs to nouns. \n",
    "    \"\"\"\n",
    "    n_nouns = 0\n",
    "    n_verbs = 0\n",
    "    for token in tokens:\n",
    "        if token.pos_ == \"NOUN\":\n",
    "            n_nouns += 1\n",
    "        elif token.pos_ == \"VERB\":\n",
    "            n_verbs += 1\n",
    "    if n_nouns == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return round(n_verbs/n_nouns,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901464de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_noun_verb_ratio(data):\n",
    "    \"\"\"\n",
    "    calculate the ratio between verbs and nouns\n",
    "    \n",
    "    data: dataframe with the text in the sentence column\n",
    "    \n",
    "    returns the dataset with new columns regarding the ver-noun-ratio\n",
    "    \"\"\"\n",
    "    for i, row in data.iterrows():\n",
    "        tokens = list(nlp(row[\"Sentence\"]))\n",
    "        data.loc[i,\"F_noun_verb_ratio\"] = verb_noun_ratio(tokens)\n",
    "        \n",
    "        # data.loc[i, \"F_avg_verb_distance\"] = distance_between_verb_particles(tokens)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f4ca72",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6927bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "verb_noun_ratio(list(nlp(\"Der Satz hat nicht mehr Verben als Nomen.\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18a3dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "verb_noun_ratio(list(nlp(\"Verben machen Texte leichter zu verstehen und zu lesen.\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d44e34",
   "metadata": {},
   "source": [
    "### Real Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72123a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = feature_noun_verb_ratio(train_data)\n",
    "data_dev = feature_noun_verb_ratio(data_dev)\n",
    "test_data = feature_noun_verb_ratio(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c04eab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_correlation_table = train_data[[\"MOS\", \"F_noun_verb_ratio\"]].corr()\n",
    "data_correlation_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bca58a",
   "metadata": {},
   "source": [
    "## Features based on Negations\n",
    "**Idea:**\n",
    "- negations turn the meaning of a sentence into the opposite.\n",
    "- double negations, turn the meaning again make sentence much more complex.\n",
    "\n",
    "**Results:**\n",
    "- no correlation between MOS and ratio of negated words (r=0.025829)\n",
    "- no correlation between MOS and ratio of negations (r=-0.044094)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3522957",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_negations_ratio(tokens):\n",
    "    \"\"\"\n",
    "    toeksn: list of spacy.Token objects\n",
    "    Calculate the ratio of negated words (including negation prefixes) to all tokens \n",
    "    and the ratio of negation words (without prefixes) to all tokens\n",
    "    \"\"\"\n",
    "    negations = [\"kein\", \"nein\", \"nicht\", \"nie\", \"niemals\"]\n",
    "    negation_prefix = [\"un\", \"des\", \"irr\"]\n",
    "    negation_suffix = [\"los\"]\n",
    "    num_real_negations = 0\n",
    "    num_negated_words = 0\n",
    "    for token in tokens:\n",
    "        if token.lemma_ in negations:\n",
    "            num_real_negations += 1\n",
    "        elif token.lemma_ != \"los\" and token.lemma_.endswith(\"los\") and token.pos_ == \"ADJ\":\n",
    "            num_negated_words += 1\n",
    "        elif token.lemma_.lower().startswith(\"un\") and token.lemma_ != \"und\" and token.pos_ == \"ADJ\":\n",
    "            num_negated_words += 1\n",
    "        elif token.lemma_.lower().startswith(\"des\") and token.pos_ == \"ADJ\":\n",
    "            num_negated_words += 1\n",
    "        elif token.lemma_.lower().startswith(\"irr\") and token.pos_ == \"ADJ\":\n",
    "            num_negated_words += 1\n",
    "    return round(num_negated_words/len(tokens),6), round(num_real_negations/len(tokens),6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401d72ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_negations(data):\n",
    "    \"\"\"\n",
    "    calculate the ratio of negated words to all tokens of a sentence\n",
    "    \n",
    "    data: dataframe with the text in the sentence column\n",
    "    \n",
    "    returns the dataset with new columns regarding the negation\n",
    "    \"\"\"\n",
    "    for i, row in data.iterrows():\n",
    "        tokens = list(nlp(row[\"Sentence\"]))\n",
    "        ratio_negated_words, ratio_negations = get_negations_ratio(tokens)\n",
    "        data.loc[i,\"F_ratio_negated_words\"] = ratio_negated_words\n",
    "        data.loc[i,\"F_ratio_negations\"] = ratio_negations\n",
    "        \n",
    "        # data.loc[i, \"F_avg_verb_distance\"] = distance_between_verb_particles(tokens)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799d57a6",
   "metadata": {},
   "source": [
    "### Real Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97b4188",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = feature_negations(train_data)\n",
    "data_dev = feature_negations(data_dev)\n",
    "test_data = feature_negations(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31bc58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_correlation_table = train_data[[\"MOS\", \"F_ratio_negated_words\", \"F_ratio_negations\"]].corr()\n",
    "data_correlation_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c2fd24",
   "metadata": {},
   "source": [
    "## Features based on Verb Tense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b08cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_verb_tense(data):\n",
    "    # todo\n",
    "    return data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2cdd7004",
   "metadata": {},
   "source": [
    "## Features based on POS Tags\n",
    "**Idea:**\n",
    "- some part of speech might occur very infrequent and make a sentence more complex\n",
    "- for more fine-grained pos tags we use the Stuttgart-Tübingen Tagset\n",
    "\n",
    "**Result**\n",
    "- strong negative correlation between punctuation marks and MOS (r=-0.6279)\n",
    "- weak negative correlation between MOS and personal pronouns (r=-0.376017)\n",
    "- weak negative correlation between MOS and finite model verbs (r=)\n",
    "- weak correlation between MOS and commas (r=0.269273)\n",
    "- weak correlation between MOS and attributive adjectives (r=0.222318)\n",
    "- all other features have no or only a weak correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dcf5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ratio_pos(tokens):\n",
    "    stts_dict = dict()\n",
    "    stts = [\"$(\", \"$,\", \"$.\", \"ADJA\", \"ADJD\", \"ADV\", \"APPO\", \"APPR\", \"APPRART\", \"APZR\", \"ART\", \"CARD\", \"FM\", \"ITJ\", \"KOKOM\", \"KON\", \"KOUI\", \"KOUS\", \"NE\", \"NN\", \"NNE\", \"PDAT\", \"PDS\", \"PIAT\", \"PIS\", \"PPER\", \"PPOSAT\", \"PPOSS\", \"PRELAT\", \"PRELS\", \"PRF\", \"PROAV\", \"PTKA\", \"PTKANT\", \"PTKNEG\", \"PTKVZ\", \"PTKZU\", \"PWAT\", \"PWAV\", \"PWS\", \"TRUNC\", \"VAFIN\", \"VAIMP\", \"VAINF\", \"VAPP\", \"VMFIN\", \"VMINF\", \"VMPP\", \"VVFIN\", \"VVIMP\", \"VVINF\", \"VVIZU\", \"VVPP\", \"XY\"]\n",
    "    for tag in stts:\n",
    "#         if \"$,\" in tag:\n",
    "#             tag = \"$comma\"\n",
    "        stts_dict[tag] = 0\n",
    "    for token in tokens:\n",
    "        if token.tag_ in stts_dict.keys():\n",
    "#             if token.tag_ == \"$,\":\n",
    "#                 stts_dict[\"$comma\"] += 1    \n",
    "#             else:\n",
    "            stts_dict[token.tag_] += 1\n",
    "        else:\n",
    "            stts_dict[\"XY\"] += 1\n",
    "    return stts_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e605f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_ratio_fpos(data):\n",
    "    for i, row in data.iterrows():\n",
    "        tokens = list(nlp(row[\"Sentence\"]))\n",
    "        new_stts_dict = get_ratio_pos(tokens)\n",
    "        for tag in new_stts_dict.keys():\n",
    "#             if \"$,\" in tag:\n",
    "#                 tag = \"$comma\"\n",
    "            # print(tag, new_stts_dict[tag], round(new_stts_dict[tag]/len(tokens),6))\n",
    "            data.loc[i,\"F_ratio_finegrained_pos_\"+tag] = round(new_stts_dict[tag]/len(tokens),6)        \n",
    "        # data.loc[i, \"F_avg_verb_distance\"] = distance_between_verb_particles(tokens)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06880e9d",
   "metadata": {},
   "source": [
    "### Real Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd1e083",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = feature_ratio_fpos(train_data)\n",
    "data_dev = feature_ratio_fpos(data_dev)\n",
    "test_data = feature_ratio_fpos(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7079d792",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.rename(columns={'F_ratio_finegrained_pos_$,': 'F_ratio_finegrained_pos_$comma'}, inplace=True)\n",
    "data_dev.rename(columns={'F_ratio_finegrained_pos_$,': 'F_ratio_finegrained_pos_$comma'}, inplace=True)\n",
    "test_data.rename(columns={'F_ratio_finegrained_pos_$,': 'F_ratio_finegrained_pos_$comma'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b959e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_cols = list(train_data.columns[train_data.nunique() <= 1])\n",
    "unique_cols "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59caa4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_ratio_fpos = [col for col in train_data.columns if col.startswith(\"F_ratio_fine\") if col not in unique_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a217f80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_correlation_table = train_data[[\"MOS\"]+feature_ratio_fpos].corr()\n",
    "data_correlation_table.sort_values(\"MOS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bbd280",
   "metadata": {},
   "source": [
    "## Features based on Imageability and concreteness\n",
    "\n",
    "- **Idea**: use features as described by Richardson (https://journals.sagepub.com/doi/10.1080/14640747508400483) for text complexity assessment\n",
    "- **Reference Lexicon**: https://www.clarin.si/repository/xmlui/handle/11356/1187\n",
    "- **Method**: \n",
    "    - first download the lexicon\n",
    "    - save it at \"data/ImageabilityConcretenessDE\"\n",
    "    - afterwards sort the lexicon\n",
    "- **Result**\n",
    "    - low negative correlation between MOS and imagebility (r=-0.092804)\n",
    "    - low negative correlation between MOS and concreteness (r=-0.140980)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4a0eb1",
   "metadata": {},
   "source": [
    "### Calculate Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82b6b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/ImageabilityConcretenessDE/ImageabilityConcretenessDE.txt\", 'r', encoding='utf-8') as f:\n",
    "    raw_scores = f.readlines()\n",
    "    \n",
    "raw_scores[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521e57a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from statistics import mean\n",
    "from typing import Generator, Iterable, List, Set, Tuple\n",
    "import random\n",
    "\n",
    "\n",
    "def split_and_remove_noise(entry: str) -> str:\n",
    "    term, imageability, concreteness = entry.strip(\"\\n\").split(\"\\t\")\n",
    "    return re.sub(r'\\A[\\W_]+|[\\W_]+\\Z', '', term), imageability, concreteness\n",
    "\n",
    "\n",
    "def lemmatize(term: str) -> List[str]:\n",
    "    doc = nlp(term)\n",
    "    return [token.lemma_ for token in doc]\n",
    "\n",
    "\n",
    "def extract_entries(entries: Iterable[str]) -> Generator:\n",
    "    for entry in entries:\n",
    "        term, imageability, concreteness = split_and_remove_noise(entry)\n",
    "        # ignore empty entries\n",
    "        if not (term == ''):\n",
    "            yield from [(lemma, imageability, concreteness) for lemma in lemmatize(term)]\n",
    "\n",
    "\n",
    "def preprocess_entries(entries: Iterable[str]) -> Set[Tuple[str]]:\n",
    "    # handle duplicate entries: mean average their scores\n",
    "    extracted_entries = list(extract_entries(entries))\n",
    "    \n",
    "    def _has_equal_lemma(e1, e2) -> bool:\n",
    "        return e1[0] == e2[0]\n",
    "    \n",
    "    def _average_duplicate_entries(e) -> Tuple[str]:\n",
    "        duplicate_entries = [entry for entry in extracted_entries if _has_equal_lemma(e, entry)]\n",
    "        if len(duplicate_entries) > 1:\n",
    "            return (e[0], mean([float(score) for _, score, _ in duplicate_entries]), mean([float(score) for _, _, score in duplicate_entries]))\n",
    "        return (e[0], float(e[1]), float(e[2]))\n",
    "    \n",
    "    return set([_average_duplicate_entries(entry) for entry in extracted_entries])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554a4dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_clean = list(preprocess_entries(raw_scores))\n",
    "scores_clean.sort(key=lambda e: e[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d9f3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(scores_clean, columns = ['Lemma', 'Imageability', 'Concreteness'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add47be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/ImageabilityConcretenessDE/ImageabilityConcretenessDE.csv\", 'w', encoding='utf-8') as f:\n",
    "    df.to_csv(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3d2387",
   "metadata": {},
   "source": [
    "### Use scores for average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0950f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "imageability_concreteness_de = pd.read_csv(\"data/ImageabilityConcretenessDE/ImageabilityConcretenessDE.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de88798d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_imagebility_concreteness(data, nlp, imageability_concreteness_data):\n",
    "    \"\"\"\n",
    "    calculate average imageability and concreteness scores over all words per sentence. if a word is not in the \n",
    "    dictionary, try if the lemma is in the dictionary, otherwise add the mean score of all words.\n",
    "    \"\"\"\n",
    "    mean_concreteness = round(imageability_concreteness_de[\"Concreteness\"].mean(),6)\n",
    "    mean_imagebility = round(imageability_concreteness_de[\"Imageability\"].mean(),6)\n",
    "\n",
    "    min_concreteness = round(imageability_concreteness_de[\"Concreteness\"].min(),6)\n",
    "    min_imagebility = round(imageability_concreteness_de[\"Imageability\"].min(),6)\n",
    "\n",
    "    max_concreteness = round(imageability_concreteness_de[\"Concreteness\"].max(),6)\n",
    "    max_imagebility = round(imageability_concreteness_de[\"Imageability\"].max(),6)\n",
    "    \n",
    "    for i, row in data.iterrows():\n",
    "        text = nlp(row[\"Sentence\"])\n",
    "        imagebility = list()\n",
    "        concreteness = list()\n",
    "        for token in text:\n",
    "            # print(token)\n",
    "            if token.text in imageability_concreteness_data[\"Lemma\"].to_list():\n",
    "                imagebility.append(imageability_concreteness_data[imageability_concreteness_data[\"Lemma\"]==token.text][\"Imageability\"].iloc[0])\n",
    "                concreteness.append(imageability_concreteness_data[imageability_concreteness_data[\"Lemma\"]==token.text][\"Concreteness\"].iloc[0])\n",
    "\n",
    "            elif token.lemma_ in imageability_concreteness_data[\"Lemma\"].to_list():\n",
    "                imagebility.append(imageability_concreteness_data[imageability_concreteness_data[\"Lemma\"]==token.lemma_][\"Imageability\"].iloc[0])\n",
    "                concreteness.append(imageability_concreteness_data[imageability_concreteness_data[\"Lemma\"]==token.lemma_][\"Concreteness\"].iloc[0])\n",
    "            else:\n",
    "                imagebility.append(mean_imagebility)\n",
    "                concreteness.append(mean_concreteness)\n",
    "                # imagebility.append(round(random.uniform(min_imagebility, max_imagebility),6))\n",
    "                # concreteness.append(round(random.uniform(min_concreteness, max_concreteness),6))\n",
    "\n",
    "        data.loc[i, \"Imagebility\"] = sum(imagebility)/len(imagebility)\n",
    "        data.loc[i, \"Concreteness\"] = sum(concreteness)/len(concreteness)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1d184e",
   "metadata": {},
   "outputs": [],
   "source": [
    "imageability_concreteness_de.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea0b027",
   "metadata": {},
   "source": [
    "### Real Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adea378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = calculate_imagebility_concreteness(train_data, nlp, imageability_concreteness_de)\n",
    "data_dev = calculate_imagebility_concreteness(data_dev, nlp, imageability_concreteness_de)\n",
    "test_data = calculate_imagebility_concreteness(test_data, nlp, imageability_concreteness_de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d733e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[[\"MOS\", \"Imagebility\", \"Concreteness\"]].corr()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a125ae1f",
   "metadata": {},
   "source": [
    "## Feature based on TSeval package\n",
    "**Idea:** \n",
    "\n",
    "The python package for text simplification evaluation contains a lot of features to highlight differences between the original sentence and simplified sentence. Some of these features might also be helpful to determine if a sentence is complex to understand.\n",
    "*Warning: Most of these features are originally calculated for English and might not language-independent.*\n",
    "\n",
    "**Result:**\n",
    "- strong correlation between MOS and count of characters (r=0.749874)\n",
    "- strong correlation between MOS and count of syllables (r=0.733147)\n",
    "- strong correlation between MOS and count of words (r=0.684206)\n",
    "- strong correlation between MOS and Flesh-Kincaid-Grading-Level (r=0.616677)\n",
    "\n",
    "- moderate correlation between MOS and parse tree height (r=0.569646)\n",
    "- moderate correlation between MOS and maximum position in frequency table (r=0.44683)\n",
    "- moderate correlation between MOS and average length of verb phrases (r=0.424383)\n",
    "- moderate correlation between MOS and average length of noun phrases (r=0.422467)\n",
    "- moderate negative correlation between MOS and type token ratio (r=-0.488884)\n",
    "\n",
    "\n",
    "- weak negative correlation between MOS and Flesh-Reading Ease score (r=-0.392505)\n",
    "- weak negative correlation between MOS and ratio of verbs(r=-0.279899)\n",
    "- weak negative correlation between MOS and ratio of pronouns (r=-0.264084)\n",
    "- weak correlation between MOS and lexical complexity score (r=0.352031)\n",
    "- weak correlation between MOS and characters per word (r=0.341423)\n",
    "- weak correlation between MOS and average length of prepositional phrase (r=0.298464)\n",
    "- weak correlation between MOS and average position in frequency table (r=0.287437)\n",
    "- weak correlation between MOS and syllables per word (r=0.244687)\n",
    "- weak correlation between MOS and if a sentence is non-projective or not (r=0.232608)\n",
    "- weak correlation between MOS and ratio of conjunctions (r=0.20639)\n",
    "- weak correlation between MOS and ratio of adjectives (r=0.200404)\n",
    "\n",
    "\n",
    "- all other features have no or only low correlation with MOS\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce28468",
   "metadata": {},
   "source": [
    "### Installation\n",
    "```\n",
    "git clone https://github.com/rstodden/text-simplification-evaluation.git\n",
    "cd text-simplification-evaluation\n",
    "pip install -e .\n",
    "pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b25f8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tseval.feature_extraction\n",
    "import pandas as pd\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475ab0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"de_core_news_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a233070",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sentence_functions = tseval.feature_extraction.get_sentence_simplification_feature_extractors()   + tseval.feature_extraction.get_sentence_feature_extractors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0731db3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_tseval_feature(data, all_sentence_functions):\n",
    "    \"\"\"\n",
    "    data: dataframe with sentences\n",
    "    all_sentence_functions: all methods of the tseval pacakge which can be applied on a sentence (and not on a simplification pair)\n",
    "    for each sentence in the dataset calculate each method of the tseval package\n",
    "    return the data with new columns regarding the tseval features\n",
    "    \"\"\"\n",
    "    for i, row in data.iterrows():\n",
    "        for method in all_sentence_functions:\n",
    "            sentence = nlp(row[\"Sentence\"])\n",
    "            data.loc[i, \"F_tseval_\"+method.__name__] = round(method(sentence, \"de\"),6)\n",
    "        print(i)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b3fc08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9fa940c2",
   "metadata": {},
   "source": [
    "### Real Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c6d9ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = calculate_tseval_feature(train_data, all_sentence_functions)\n",
    "data_dev = calculate_tseval_feature(data_dev, all_sentence_functions)\n",
    "test_data = calculate_tseval_feature(test_data, all_sentence_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9591bd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_cols = list(train_data.columns[train_data.nunique() <= 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef61fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.drop(unique_cols,1)\n",
    "data_dev = data_dev.drop(unique_cols,1)\n",
    "test_data = test_data.drop(unique_cols,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca626d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [col for col in train_data.columns if col.startswith(\"F_tseval_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b075d8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_correlation_table = train_data[[\"MOS\"]+feature_cols].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b1fb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_correlation_table.sort_values(\"MOS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ab9103",
   "metadata": {},
   "source": [
    "## Features based on Perplexity Score of Language Models\n",
    "- description of perplexity in huggingface: https://huggingface.co/docs/transformers/perplexity\n",
    "- Implementation and example of perplexity in huggingface: https://github.com/huggingface/datasets/blob/master/metrics/perplexity/perplexity.py\n",
    "- Idea: \n",
    "    - The more frequent the words and the more frequent the word order in a sentence, the easier the sentence and the more likely a language model can predit the sentence.\n",
    "    - The higher the perplexity score, the more unlikely that the language would predict the input the sentence and the more complex the sentence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daec2f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datasets\n",
    "!pip install transformers\n",
    "\n",
    "# install latest version of datasets \n",
    "!pip install git+https://github.com/huggingface/datasets\n",
    "    \n",
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f1804f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datasets import load_metric \n",
    "import pandas\n",
    "import torch\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048c2153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check installed version of dataset package\n",
    "!pip freeze | grep datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca408bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexity = evaluate.load(\"perplexity\", module_type=\"metric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47e16f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppl_of_sent(input_texts, model_id, perplexity=evaluate.load(\"perplexity\", module_type=\"metric\")):\n",
    "    \"\"\"\n",
    "    Calculate the perplexity value of the input texts on the specified model.\n",
    "    input texts: string or list of sentences\n",
    "    model_id: name of a model in huggingaface\n",
    "    perplexity: method to calculate the perplexity score\n",
    "    \n",
    "    returns the result score\n",
    "    \"\"\"\n",
    "    \n",
    "    results = perplexity.compute(input_texts=input_texts, model_id=model_id)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5790c245",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ppl(data, models):\n",
    "    \"\"\"\n",
    "    Calculate the perplexity value of the input texts in a specified dataset on the specified model.\n",
    "    data: dataframe with input text\n",
    "    models: list of names of models in huggingface \n",
    "    \n",
    "    returns the dataset with new columns regarding the perplexity features\n",
    "    \"\"\"\n",
    "    for model in models:\n",
    "        for i, row in data.iterrows():\n",
    "            ppl = perplexity.compute(input_texts=[str(row[\"Sentence\"])], model_id=model)[\"mean_perplexity\"]\n",
    "            data.loc[i, \"ppl_\"+model.split(\"/\")[-1]] = ppl\n",
    "            if not i%100:\n",
    "                print(i, model)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de800fc3",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d650bc2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd99b11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ppl_of_sent([\"Das klingt gut.\"], \"benjamin/gerpt2\", perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2bcef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl_of_sent([\"Das klingen gut.\"], \"benjamin/gerpt2\", perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb430cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl_of_sent([\"Einige Geldautomaten können nicht nur Banknoten verarbeiten, sondern auch Münzen.\"], \"benjamin/gerpt2\", perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e9d5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl_of_sent([\"Einige Geldautomaten können Banknoten und auch Münzen verarbeiten.\"], \"benjamin/gerpt2\", perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ced36c",
   "metadata": {},
   "source": [
    "### Real Data\n",
    "- add perplexity features to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3859d4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = calculate_ppl(train_data, [\"benjamin/gerpt2\", \"facebook/mbart-large-cc25\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8212638a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data = calculate_ppl(dev_data, [\"benjamin/gerpt2\", \"facebook/mbart-large-cc25\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c159bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = calculate_ppl(test_data, [\"benjamin/gerpt2\", \"facebook/mbart-large-cc25\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1912531c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.corr([[\"MOS\", \"ppl_gerpt2\", \"ppl_mbart-large-cc25\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3d5774",
   "metadata": {},
   "source": [
    "## Text Leveling as Feature for Complexity Prediction\n",
    "\n",
    "- **Idea:** The older the target group of a text, the more difficult to read is the text. \n",
    "- **Data**: [Lexica-Corpus](https://github.com/fhewett/lexica-corpus) with parallelen Wikipedia texts for children, youth and adults\n",
    "- **Label:** children (0), youth (1), adults (2)\n",
    "- **Method**: Sequence-Labeling.\n",
    "    - split the lexica-corpus texts into sentences and label the sentences with their target group (label)\n",
    "    - Fine-tune a Transformer model with these data (sentence - label)\n",
    "    - predict the label of the complexity dataset (GermEval) with the fine-tuned model\n",
    "- **Results:** \n",
    "- moderate correlation between MOS and text leveling feature (r=0.587874)\n",
    "\n",
    "See separate [notebook called \"Feature_Text_Leveling\"](Feature_Text_Leveling.ipynb) for the code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1b1852",
   "metadata": {},
   "source": [
    "## Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afff8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c83861",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"data/feats\"):\n",
    "    os.makedirs(\"data/feats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240256fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv(\"data/feats/train_1.csv\", index=False)\n",
    "data_dev.to_csv(\"data/feats/validation_1.csv\", index=False)\n",
    "test_data.to_csv(\"data/feats/test_1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c208c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
